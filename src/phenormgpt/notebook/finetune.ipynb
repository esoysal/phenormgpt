{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load terminology\n",
    "from base.load_hpo import hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from base.load_dataset import load_train_dataset, load_val_dataset\n",
    "train_dataset = load_train_dataset()\n",
    "val_dataset = load_val_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI client\n",
    "from config.openai_config import openai_api_key\n",
    "from prompting.openai_client import FinetuningOpenAIClient\n",
    "openai_client = FinetuningOpenAIClient(openai_api_key, model='gpt-3.5-turbo-0613')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompting\n",
    "from prompting.generate_messages import get_openai_finetuning_messages\n",
    "from prompting.prompts import *\n",
    "\n",
    "# Create datasets for OpenAI API\n",
    "train_messages = get_openai_finetuning_messages(train_dataset, hpo=hpo, system_message=SYSTEM_MESSAGE,\n",
    "                                                user_message_wrapper=USER_MESSAGE_WRAPPER,\n",
    "                                                assistant_message_table_header=ASSISTANT_MESSAGE_TABLE_HEADER,\n",
    "                                                filename='train.json')\n",
    "val_messages = get_openai_finetuning_messages(val_dataset, hpo=hpo, system_message=SYSTEM_MESSAGE,\n",
    "                                              user_message_wrapper=USER_MESSAGE_WRAPPER,\n",
    "                                              assistant_message_table_header=ASSISTANT_MESSAGE_TABLE_HEADER,\n",
    "                                              filename='val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload datasets to OpenAI API\n",
    "import os\n",
    "from config.config import FINE_TUNE_DIR\n",
    "openai_client.upload_train_file(os.path.join(FINE_TUNE_DIR, 'train.json'))\n",
    "openai_client.upload_val_file(os.path.join(FINE_TUNE_DIR, 'val.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune a model\n",
    "openai_client.model = 'gpt-3.5-turbo-0613'\n",
    "openai_client.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve job\n",
    "openai_client.retrieve_finetune_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve finetuned model name if the job succeeded\n",
    "openai_client.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to using finetuned model for future requests\n",
    "openai_client.use_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example request\n",
    "item = val_messages[0]\n",
    "response = openai_client.get_response(item['messages'])\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
