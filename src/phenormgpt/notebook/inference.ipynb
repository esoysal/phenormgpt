{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797be48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e104b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load terminology\n",
    "from base.load_hpo import hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from base.load_dataset import *\n",
    "annotated_dataset = load_annotated_dataset() # train + val\n",
    "inference_dataset = load_test_dataset()\n",
    "handpicked_dataset = load_handpicked_dataset() # handpicked examples from train + val to cover tricky cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c83ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI client\n",
    "from config.openai_config import openai_api_key\n",
    "from prompting.openai_client import OpenAIClient\n",
    "openai_client = OpenAIClient(openai_api_key, model='gpt-3.5-turbo-0613')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8617ad-c418-491c-b684-cdf882d51848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load prompting\n",
    "from prompting.generate_messages import get_openai_messages\n",
    "from prompting.prompts import *\n",
    "\n",
    "# Generate messages to submit to OpenAI API.\n",
    "# Optional: Use a few shot dataset for few-shotting annotated examples.\n",
    "inference_dataset_messages = get_openai_messages(inference_dataset, hpo, system_message= SYSTEM_MESSAGE,\n",
    "                                                 user_message_wrapper = USER_MESSAGE_WRAPPER,\n",
    "                                                 assistant_message_table_header = ASSISTANT_MESSAGE_TABLE_HEADER,\n",
    "                                                 few_shot_dataset = annotated_dataset, few_shot_k = 10, few_shot_k_min = 3,\n",
    "                                                 hand_picked_dataset = handpicked_dataset, include_response=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ccc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated message dataset to cache.\n",
    "from util.caching import save_json_to_cache\n",
    "save_json_to_cache('inference_dataset_messages.json', inference_dataset_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference\n",
    "test_response = openai_client.get_response(inference_dataset_messages[0])\n",
    "print(test_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7041ad6-17ae-4137-be75-b807bde9795a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run inference\n",
    "from tqdm import tqdm\n",
    "inference_responses = []\n",
    "for messages in tqdm(inference_dataset_messages):\n",
    "    observation = messages[-1]['content']\n",
    "    response = openai_client.get_response(messages)\n",
    "    \n",
    "    inference_responses.append({\n",
    "        'observation': observation,\n",
    "        'response': response\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625975e5-19d0-4196-a289-5921b5001c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save responses for the dataset to cache.\n",
    "save_json_to_cache('inference_responses.json', inference_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e179e9-fe37-4f44-91d5-970c1fd86b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load responses as a dataset object\n",
    "import os\n",
    "from base.init_dataset import init_dataset_from_openai_responses\n",
    "from util.caching import CACHE_DIR\n",
    "response_dataset = init_dataset_from_openai_responses(os.path.join(CACHE_DIR, 'inference_responses.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635232f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "from matching.normalization import normalize_term\n",
    "for observation in tqdm(response_dataset.observations):\n",
    "    observation.terms = [normalize_term(term) for term in observation.terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions\n",
    "from config.config import OUTPUT_DIR\n",
    "response_dataset.write_to_tsv(os.path.join(OUTPUT_DIR, 'BioCreativeVIII3_TestSetPreds.tsv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
